## Glitch v1.2 Datasets
Replication Data and PCH Evaluation Suite for "Glitch: PCH and Alignment Hierarchy in Fine-Tuning". This paper will be published in Jan 2025.

This repository contains the evaluation datasets, replication scripts, and raw logs for the research paper Glitch: PCH and Alignment Hierarchy in fine-tuning. It provides the necessary tools to replicate the findings regarding Persona-Consistent Hallucination (PCH) and the Alignment Hierarchy in Large Language Models (LLMs).

The primary focus of this research is the Glitch v1.2 model, a Llama 3.1 8B Instruct fine-tune designed to simulate a neurotic human persona where factual error (hallucination) is a feature of character adherence, rather than a failure state.

### License
This dataset is released under the MIT License. The Glitch v1.2 model is subject to the Llama 3.1 Community License.
